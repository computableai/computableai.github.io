{
    "pages": [
        {
            "title": "Boltzmann Machines: Differentiation Work", 
            "text":"I recently read The Miracle of the Boltzmann Machine, and it&#39;s so compelling that I&#39;ve been thinking about it ever since. I intend to write much more on Boltzmann Machines in the future, but here I&#39;m just going to show my work differentiating the objective function. Given¶ Objective function $$L(W) := \mathbb{E}_{D(V)} [log P(V)]$$ and probability of a given BM state $X=(V,H)$ $$P(X) := P(V,H) := {e^{X^TWX/2}\over {\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}}$$ $$P(V) := \sum_H P(V,H) = \frac{\sum_H e^{X^TWX/2}}{\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}$$ where $W$ is the BM transition matrix, assuming $w_{ij}=w_{ji}$ Want to show¶$$\frac{\partial L}{\partial w_{ij}} = \mathbb{E}_{D(V)P(H|V)}[x_ix_j]-\mathbb{E}_{P(V,H)}[x_ix_j]$$Proof¶ Definition of expected value $$L(W)=\mathbb{E}_{D(V)} [\log P(V)] = \sum_V D(V)\log P(V)$$ Let $f = logP(V)$ $$\frac{\partial L}{\partial f} = \sum_V D(V)\frac{\partial f}{\partial w_{ij}}$$ Chain rule $$\frac{\partial f}{\partial w_{ij}} = {\frac{\partial P(V)}{\partial w_{ij}} \over P(V)}$$ Expand $P(V)$ $$\frac{\partial P(V)}{\partial w_{ij}} = \frac{\partial}{\partial w_{ij}}\left[\sum_H P(V,H)\right] = \frac{\partial}{\partial w_{ij}}\left[\sum_H {e^{X^TWX/2}\over {\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}}\right] = \sum_H \frac{\partial}{\partial w_{ij}}\left[{e^{X^TWX/2}\over {\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}}\right]$$ Quotient rule $$\frac{\partial P(V)}{\partial w_{ij}} =\sum_H \frac{\frac{\partial}{\partial w_{ij}}\left[e^{X^TWX/2}\right]{\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}-e^{X^TWX/2} \frac{\partial}{\partial w_{ij}}\left[{\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}\right]}{\left({\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}\right)^2}$$ Chain rule, and notice $\frac{\partial}{\partial w_{ij}}\left[W\right]$ is $0$ everywhere except $w_{ij}$, so $$\frac{\partial}{\partial w_{ij}}\left[e^{X^TWX/2}\right] = \frac{\partial}{\partial w_{ij}}\left[X^TWX/2\right] e^{X^TWX/2} = x_ix_je^{X^TWX/2}$$ So #5 becomes $$\frac{\partial P(V)}{\partial w_{ij}} = \sum_H \frac{x_ix_je^{X^TWX/2}{\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}-e^{X^TWX/2} \sum_{X&#39;}x&#39;_ix&#39;_je^{X&#39;^TWX&#39;/2}}{\left({\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}\right)^2}$$ Separating terms $$\frac{\partial P(V)}{\partial w_{ij}} = \sum_H\left[\frac{x_ix_je^{X^TWX/2}{\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}}{\left({\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}\right)^2}\right]-\sum_H\left[\frac{e^{X^TWX/2} \sum_{X&#39;}x&#39;_ix&#39;_je^{X&#39;^TWX&#39;/2}}{\left({\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}\right)^2}\right]$$ Cancelling and moving factors outside sums $$\frac{\partial P(V)}{\partial w_{ij}} = \sum_H\left[\frac{x_ix_je^{X^TWX/2}}{{\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}}\right]-\frac{\sum_H\left[e^{X^TWX/2}\right] \sum_{X&#39;}x&#39;_ix&#39;_je^{X&#39;^TWX&#39;/2}}{\left({\sum_{X&#39;} e^{X&#39;^TWX&#39;/2}}\right)^2}$$ Definition of $P(V,H)$ and $P(V)$ $$\frac{\partial P(V)}{\partial w_{ij}} = \sum_H\left[x_ix_jP(V,H)\right]-P(V) \sum_{X&#39;}\left[x&#39;_ix&#39;_jP(V&#39;,H&#39;)\right]$$ Substituting #10 into #3 and #3 into #2 we have $$\frac{\partial L}{\partial w_{ij}} = \sum_VD(V)\left[\frac{\sum_H\left[x_ix_jP(V,H)\right]-P(V) \sum_{X&#39;}\left[x&#39;_ix&#39;_jP(V&#39;,H&#39;)\right]}{P(V)}\right]$$ Separating into two terms $$\frac{\partial L}{\partial w_{ij}} = \sum_V\left[D(V)\sum_H\left[\frac{x_ix_jP(V,H)}{P(V)}\right]\right]-\sum_V\left[D(V)P(V)\sum_{X&#39;}\left[x&#39;_ix&#39;_jP(V&#39;,H&#39;)\right]\right]$$ Definition of conditional probability $$\frac{\partial L}{\partial w_{ij}} = \sum_V\sum_H\left[x_ix_jD(V)P(H|V)\right]-\sum_VD(V)\sum_{X&#39;}\left[x&#39;_ix&#39;_jP(V&#39;,H&#39;)\right]$$ $\sum_VD(V)=1$, combining sums, and $X=(V,H)$ $$\frac{\partial L}{\partial w_{ij}} =\sum_{(V,H)}\left[x_ix_jD(V)P(H|V)\right]-\sum_{(V&#39;,H&#39;)}\left[x&#39;_ix&#39;_jP(V&#39;,H&#39;)\right]$$ Definition of expected value $$\frac{\partial L}{\partial w_{ij}} = \mathbb{E}_{D(V)P(H|V)}[x_ix_j]-\mathbb{E}_{P(V,H)}[x_ix_j]$$ $\square$ if (!document.getElementById(&#39;mathjaxscript_pelican_#%@#$@#&#39;)) { var mathjaxscript = document.createElement(&#39;script&#39;); mathjaxscript.id = &#39;mathjaxscript_pelican_#%@#$@#&#39;; mathjaxscript.type = &#39;text/javascript&#39;; mathjaxscript.src = &#39;//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#39;; mathjaxscript[(window.opera ? &#34;innerHTML&#34; : &#34;text&#34;)] = &#34;MathJax.Hub.Config({&#34; + &#34; config: [&#39;MMLorHTML.js&#39;],&#34; + &#34; TeX: { extensions: [&#39;AMSmath.js&#39;,&#39;AMSsymbols.js&#39;,&#39;noErrors.js&#39;,&#39;noUndefined.js&#39;], equationNumbers: { autoNumber: &#39;AMS&#39; } },&#34; + &#34; jax: [&#39;input/TeX&#39;,&#39;input/MathML&#39;,&#39;output/HTML-CSS&#39;],&#34; + &#34; extensions: [&#39;tex2jax.js&#39;,&#39;mml2jax.js&#39;,&#39;MathMenu.js&#39;,&#39;MathZoom.js&#39;],&#34; + &#34; displayAlign: &#39;center&#39;,&#34; + &#34; displayIndent: &#39;0em&#39;,&#34; + &#34; showMathMenu: true,&#34; + &#34; tex2jax: { &#34; + &#34; inlineMath: [ [&#39;$&#39;,&#39;$&#39;] ], &#34; + &#34; displayMath: [ [&#39;$$&#39;,&#39;$$&#39;] ],&#34; + &#34; processEscapes: true,&#34; + &#34; preview: &#39;TeX&#39;,&#34; + &#34; }, &#34; + &#34; &#39;HTML-CSS&#39;: { &#34; + &#34; linebreaks: { automatic: true, width: &#39;95% container&#39; }, &#34; + &#34; styles: { &#39;.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn&#39;: {color: &#39;black ! important&#39;} }&#34; + &#34; } &#34; + &#34;}); &#34;; (document.body || document.getElementsByTagName(&#39;head&#39;)[0]).appendChild(mathjaxscript); }", 
            "tags": "Commentary", 
            "loc": "https://computable.ai/articles/2019/Mar/10/boltzmann-machines-differentiation-work.html"
        },
        {
            "title": "Inaugural Post", 
            "text":"This post begins the Computable AI blog, a machine intelligence blog from a handful of DRL practitioners, intended to crystalize, internalize, share, and explain. I found few beginner resources for DRL when I began, and since I have a passion for teaching, this seemed a likely area in which to make a dent. I also serve as the &#34;Director of Applied Sciences&#34; for a startup software company, and the AI team must occasionally indoctrinate new members. This provides us with a convenient target audience, as well as an expanding pool of co-authors. Finally, my own education in DRL is incomplete, so this will serve partly as a record of my own journey. I hope it helps you. if (!document.getElementById(&#39;mathjaxscript_pelican_#%@#$@#&#39;)) { var mathjaxscript = document.createElement(&#39;script&#39;); mathjaxscript.id = &#39;mathjaxscript_pelican_#%@#$@#&#39;; mathjaxscript.type = &#39;text/javascript&#39;; mathjaxscript.src = &#39;//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#39;; mathjaxscript[(window.opera ? &#34;innerHTML&#34; : &#34;text&#34;)] = &#34;MathJax.Hub.Config({&#34; + &#34; config: [&#39;MMLorHTML.js&#39;],&#34; + &#34; TeX: { extensions: [&#39;AMSmath.js&#39;,&#39;AMSsymbols.js&#39;,&#39;noErrors.js&#39;,&#39;noUndefined.js&#39;], equationNumbers: { autoNumber: &#39;AMS&#39; } },&#34; + &#34; jax: [&#39;input/TeX&#39;,&#39;input/MathML&#39;,&#39;output/HTML-CSS&#39;],&#34; + &#34; extensions: [&#39;tex2jax.js&#39;,&#39;mml2jax.js&#39;,&#39;MathMenu.js&#39;,&#39;MathZoom.js&#39;],&#34; + &#34; displayAlign: &#39;center&#39;,&#34; + &#34; displayIndent: &#39;0em&#39;,&#34; + &#34; showMathMenu: true,&#34; + &#34; tex2jax: { &#34; + &#34; inlineMath: [ [&#39;$&#39;,&#39;$&#39;] ], &#34; + &#34; displayMath: [ [&#39;$$&#39;,&#39;$$&#39;] ],&#34; + &#34; processEscapes: true,&#34; + &#34; preview: &#39;TeX&#39;,&#34; + &#34; }, &#34; + &#34; &#39;HTML-CSS&#39;: { &#34; + &#34; linebreaks: { automatic: true, width: &#39;95% container&#39; }, &#34; + &#34; styles: { &#39;.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn&#39;: {color: &#39;black ! important&#39;} }&#34; + &#34; } &#34; + &#34;}); &#34;; (document.body || document.getElementsByTagName(&#39;head&#39;)[0]).appendChild(mathjaxscript); }", 
            "tags": "Miscellany", 
            "loc": "https://computable.ai/articles/2019/Feb/16/inaugural-post.html"
        },
        {
            "title": "About", 
            "text":"Welcome to Computable AI blog, a machine intelligence blog from a handful of DRL practitioners, intended to crystalize, internalize, share, and explain. I found few beginner resources for DRL when I began, and since I have a passion for teaching, this seemed a likely area in which to make a dent. I also serve as the &#34;Director of Applied Sciences&#34; for a startup software company, and the AI team must occasionally indoctrinate new members. This provides us with a convenient target audience, as well as an expanding pool of co-authors. Finally, my own education in DRL is incomplete, so this will serve partly as a record of my own journey. I hope it helps you.", 
            "tags": "pages", 
            "loc": "https://computable.ai/pages/about.html"
        }        
    ]
}