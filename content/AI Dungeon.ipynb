{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- title: Look at This: AI Dungeon\n",
    "- summary: AI Dungeon is an endless text adventure game with impressively open natural language interactions, implemented on a fine-tuned GPT-2.\n",
    "- author: Daniel Cox\n",
    "- date: 2019-12-08\n",
    "- category: Look at This\n",
    "- image: https://pcc4318.files.wordpress.com/2018/02/asset-1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've been thinking about GPT-2 off and on lately, wondering what near-term value I might put it to. Then a friend pointed me to [AI Dungeon](http://www.aidungeon.io/), an exploration from the BYU Perception, Control, and Cognition Lab, which uses GPT-2 to generate an open-world text adventure game. It's not perfect, but it is pretty impressive and fun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's my first interaction with it:\n",
    "\n",
    "```\n",
    "Generating story...\n",
    "You are Daniel, a wizard living in the kingdom of Larion. You have a staff and\n",
    " a spellbook. You finish your long journey and finally arrive at the ruin you've\n",
    " been looking for. You look around and see that it's not much different than\n",
    " when you left it. A few trees here and there, but nothing has changed since\n",
    " then.\n",
    "As you enter the ruins, you hear some noise outside. It sounds like voices\n",
    "> hide\n",
    "You quickly turn to run away from the sound, but you don't get far before you're\n",
    " surrounded by several men with guns. They point their weapons at you as they\n",
    " demand to know where you came from.\n",
    "> say \"I am Daniel, wizard of Larion! And who, may I ask, are you?\"\n",
    "\"Who are you?\" You say, trying to keep calm.\n",
    "\"We are the guards assigned to protect this place. We have come here because\n",
    " we heard the voices coming from inside\". One of them says.\n",
    "> say \"Certainly then we are friends, for I have sought these ruins for years, only to learn from them their wisdom.\"\n",
    "The man looks at you with surprise. He is obviously surprised that you would\n",
    " seek out the ruins.\n",
    "\"Friends? What do you mean friend? These ruins were built by an ancient race\n",
    " long dead. How could you possibly be friends with us?\" he asks\n",
    "> say \"I see no conflict. You guard the ruins, and I seek their wisdom as an end in itself. How else did you become their guardians but by valuing them on their own merits and for no mercenary purpose?\"\n",
    "He seems to take it all in, and nods his head.\n",
    "\"Very well, we will allow you to pass. But if you find anything strange or dangerous,\n",
    " please tell me immediately. I want to know what has happened here\".\n",
    "> Walk in\n",
    "You enter the building, which is quite large. The walls are made of stone, and\n",
    " there are many doors, each with a different symbol on them. There are also many\n",
    " statues of wizards standing around, some of them holding books\n",
    "``` \n",
    "\n",
    "Things go down-hill from there, though unfortunately I didn't think to save the rest. They have others' recorded sessions at the main site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do notice that, like other GPT-2 examples, it often confuses pronoun referents, (a common NLP problem in general), plurality, and macro-scale plot points, but I think harping on its imperfections is beside the point. The number of times that it gets the above things _right_ is shocking, and enough for the game to be playable. The PCCL fine-tuned GPT-2 on a text adventure corpus, and it seems likely that further improvements could be made to the game with more fine-tuning and perhaps some post-processing.\n",
    "\n",
    "Now, I don't particularly care about text adventure games _per se_, but what really gets me about AI Dungeon is its demonstration of the enormous potential for improved language models to interact naturally with humans.\n",
    "\n",
    "Chat bots are _terrible_. Really terrible. But we can improve that with Transformer-based models, apparently. Likewise, search has been pretty terrible at figuring out what a naive searcher wants, but Transformers are being applied to that problem too in actual, popular search engines. In just the past _two months_, [both Google](https://www.blog.google/products/search/search-language-understanding-bert/) [and Bing](https://azure.microsoft.com/en-us/blog/bing-delivers-its-largest-improvement-in-search-experience-using-azure-gpus/) have both integrated BERT to improve natural-language-search understanding. The original BERT paper was released in October of 2018, so that's under a year from a breakthrough in attentional models, and production code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other thing I like is that the game is [hosted and run from inside Google Colab](https://colab.research.google.com/github/nickwalton/AIDungeon/blob/master/AIDungeon_2.ipynb). Text adventures (and other text-based human interaction experiments) don't require a lot of UI, so that strikes me as a great idea that many others should emulate.\n",
    "\n",
    "You can peruse the AI Dungeon [source code here](https://github.com/nickwalton/AIDungeon).\n",
    "\n",
    "Play a quick game yourself and post your results in the comments!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
