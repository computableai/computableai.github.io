{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- title: Cox's Theorem\n",
    "- summary: asdf\n",
    "- author: Daniel Cox\n",
    "- date: 2019-10-20\n",
    "- category: arXiv highlights\n",
    "- image: /static/images/arXiv.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranging farther afield\n",
    "\n",
    "Today I'll be taking advantage of my stated intention to pull back from the _recent_ papers stream occasionally to look at papers for their impact or fundamental importance as I see it. So today I'm doing something unusual, highlighting a paper not from last week, but from _four years_ ago, [Cox's Theorem and the Jaynesian Interpretation of Probability](https://arxiv.org/abs/1507.06597).\n",
    "\n",
    "I've been reading a book by E. T. Jaynes, called [Probability Theory: The Logic of Science](https://www.amazon.com/Probability-Theory-Science-T-Jaynes/dp/0521592712), purported to be a brilliant and practical exposition of the Bayesian view of probability theory, partially on [the recommendation of another AI researcher](https://www.lesswrong.com/posts/kXSETKZ3X9oidMozA/the-level-above-mine). The thoughts of an ideal reasoner would have Bayesian structure, so I am both personally and professionally interested in mastering the concepts.\n",
    "\n",
    "Cox's theorem is an attempt to derive probability theory from a small, common-sense set of uncontroversial desiderata, and to demonstrate its uniqueness as an extension of two-valued (true/false) logic to degrees of belief. That's a big deal. As today's paper mentions, Peter Cheeseman [has called](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8640.1988.tb00091.x) Cox's theorem the \"strongest argument for the use of standard (Bayesian) probability theory\". But Cox's theorem is non-rigorous as originally formulated, and many people have patched up the holes for use in their various fields. Often today, if someone refers to \"Cox's theorem\", they usually mean one of the fixed-up versions.\n",
    "\n",
    "Jaynes' version unfortunately contains a mistake, and today's paper fixes it by replacing some of the axioms with the simple requirement that probability theory remain consistent with respect to repeated events.\n",
    "\n",
    "It may be difficult without reading the book to see why this paper is important to AI, so perhaps in the near future I'll discuss that at greater length. For today, however, I'll simply be explaining each of the axioms, and setting you up to read the paper more easily. It's worth it, to ground your confidence in the interpretation of probability theory as a _logical system_, extending true-false logic to handle uncertainty, so you can reap the associated benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Axioms\n",
    "$\\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\F}{\\mathscr{F}}$\n",
    "\n",
    "This paper proposes a new axiomatization of probability theory, with five axioms. As a variant of Cox's theorem, these axioms are supposed to represent a set of \"common sense\" desiderata for a logical system under uncertainty. That is, each of these axioms are things we naturally want to be true of any logical system under uncertainty. Cox's original axioms were more intuitively essential to me, however, so I'll also try to give justifications for demanding each of the following axioms, as well as explaining them technically.\n",
    "\n",
    "Remember the ultimate goal is to _build_ probability theory up from a minimal set of absolute requirements for _any_ logical system. The punchline is that probability theory as described historically by greats like Kolmogorov turns out to be the _unique_ extension of true-false logic under uncertainty, and we can derive it from \"common sense\".\n",
    "\n",
    "To emphasize the point that while we're writing these axioms we haven't yet got _probability_, I'll refer to our measure of certainty/uncertainty as \"plausibility\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Plausibility must be representable by a real number\n",
    "\n",
    "> Let $\\Omega$ be a set and $\\mathscr{F}$ be a $\\sigma$-algebra on $\\Omega$.\n",
    "> \n",
    "> Let $\\P: \\F \\times (\\F \\setminus \\emptyset) \\rightarrow R \\subseteq \\mathbb{R}$ be a function, written using notation $\\P(A|B)$.\n",
    "\n",
    "It makes intuitive sense that we should be able to measure our uncertainty on a smooth, finite scale, so it makes sense to demand that our plausibility scale be chosen from some definite subset of the reals.\n",
    "\n",
    "$\\F$ being \"a $\\sigma$-algebra on $\\Omega$\" means that it is the set of every subset of $\\Omega$ (including $\\Omega$ and $\\emptyset$), is closed under complement, and is closed under countable unions. (Being \"closed under\" some operation means that taking that operation on any element in the set yields an element that's also defined to be in the set.) The idea is that $\\Omega$ comprises all primitive events, and $\\F$ therefore includes every possible logical combination of these primitive events, in a way that makes it eqivalent to a Boolean algebra.\n",
    "\n",
    "I found it clarifying that $\\P(\\Omega)=1$. That's what made it click for me that a set in $\\F$ represents a disjunction of primitive events, and $\\Omega$ contains _all_ primitive events, so $\\P(\\Omega)$ is the probability that _anything_ happens.\n",
    "    \n",
    "$\\P(A|B)$ is a function of two arguments $A,B \\in \\mathscr{F}$, and B cannot be empty. The interpretation is, \"The probability of some event A, given that event B is true.\" The second argument cannot be empty, Jaynes often describes it as \"the background information\", including everything else known (such as the rules of probability themselves, and the number of penguins in Antarctica).\n",
    "\n",
    "The arguments of $\\P$ are sets, but as the paper mentions, \"by [Stone's Representation Theorem](https://www.jstor.org/stable/1989664), every Boolean algebra is isomorphic to an algebra of sets\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sequential continuity\n",
    "\n",
    "> We have that\n",
    "> $$A_1 \\subseteq A_2 \\subseteq A_3 \\subseteq\\ldots \\text{ such that } A_i \\nearrow A \\text{ implies } \\P (A_i | B)\\nearrow \\P(A | B )$$\n",
    "> for all $A, A_i, B$.\n",
    "\n",
    "Another intuitive requirement for a system of logical inference is that our plausibility measure return arbitrarily small differences in plausibility for arbitrarily small changes in truth value. This concept is also known as \"continuity\".\n",
    "\n",
    "If you can arrange a sequence of events (sets) so that earlier events (e.g., $A_1$) are included in later events (e.g., $A_3$), then there is \"sequential continuity\" between earlier sets and later sets in this sequence. In the notation of the paper, $A_1 \\nearrow A_3$.\n",
    "\n",
    "What this axiom is saying is that as long as there is sequential continuity between two logical propositions, there is also sequential continuity between their plausibilities. This formalizes our requirement for continuity. Also notice that if $\\P (A_i | B)\\nearrow \\mathbb{P}(A | B )$ then $\\P (A_i | B) \\leq \\mathbb{P}(A | B )$, because our definition of sequential continuity also implies that the cardinality of the sets is non-decreasing. This will be useful reading the proof. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decomposability\n",
    "\n",
    "> $\\P(AB | C )$ can be written as\n",
    "> $$\\P(A | C ) \\circ \\P(B | AC)$$\n",
    "> for some some function $\\circ : (R \\times R) \\rightarrow R$.\n",
    "\n",
    "This is the first axiom that I had trouble seeing as intuitive. It represents the demand that plausibilities of compound propositions be decomposable into plausibilities of the their constituents, and that that decomposition has a particular form. It's the demand that it follow a particular form that seems somewhat arbitrary to me at first. Of course we would want to be able to decompose compound uncertainty into more fundamental elements, or else probability theory wouldn't be very useful. But why should it take the form described of $\\circ$?\n",
    "\n",
    "The answer is that this form is _minimal_ for decomposability. That is, it's the weakest statement that could be made about the details of decomposition. In English: \"The plausibility of A _and_ B is a function of the plausibility of one of those (say, $A$), and the plausibility of the other ($B$) once we can assume $A$ is true.\"\n",
    "\n",
    "Note that logical conjunctions are commutative ($AB = BA$), so by this axiom $\\P(AB | C )$ can _also_ be written as $\\P(B | C ) \\circ \\P(A | BC)$. They prove later also that $\\circ$ is commutative, but that is not assumed in the axioms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Negation\n",
    "\n",
    "> There exists a function $N : R \\rightarrow R$ such that \n",
    "> $$\n",
    "\\P(A^c | B)= N[ \\P(A | B)]\n",
    "$$\n",
    "> for all $A,B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Consistency under extension\n",
    "\n",
    "> If $(\\Omega, \\mathscr{F}, \\P)$ satisfies the axioms above, then $(\\Omega \\times \\Omega, \\mathscr{F} \\otimes \\mathscr{F}, \\P \\operatorname{\\circ} \\P)$ must as well, i.e., the definition $\\P(A \\times B | C \\times D) = \\P(A | C) \\circ \\P(B | D)$ is consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parting thoughts\n",
    "\n",
    "1. I could make this a lot clearer for people with less set theory, group theory, or probability theory background. If that would be helpful to you, please leave me a comment on what specifically didn't make sense so I can get a feel for my audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
